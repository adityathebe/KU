# 3. Problem Solving

## Starting Notes
- **Reflex agents** ( *chapter 2* ) base their actions on a direct mapping from states to actions
- They cannot operate well in environments for which the mappings are too large to store due to which learning takes very long time.
- **Goal-based agents**, however, conside future actions and the desirability of outcomes
- **Problem-solving agent** is one kind of goal-based agent
- Problem-solving agents decide what to do by finding sequences of actions that lead to desirable states
- There are **uninformed** and **informed** search algorithms

## Problem-Solving Agents

- intelligent agents are supposed to maximize their performance and this can be achieved if the agent can adopt a goal and aim at satisfying it.
- **Goal formulation**, based on the current situation and the agent's performance measure, is the first step in problem solving.
- Goal is a set of world states - exactly those states in which the goal is satisfied
- **Problem formulation** is the process of deciding what actions and states to consider, given a goal.
- A **Search Algorithm** takes *problem* as input and returns a *solution* in the form of an action sequence
- **Execution Phase** is the phase in which the actions determined by the search algorithm are carried out

## Well-defined problems and solutions

A solution to a problem is a path from the initial state to a goal state

**Four components to formally define a problem**
- Initial states
- Successor function
  - *State Space = Initial State + Successor fn*
  - *State space is the set of all states reachable from the initial state*
- Goal Test
  - takes in a state and returns if the state is a (or one of the ) goal state(s)
  - there can be one goal state or a set of goal states
- Path Cost
  - assigns a numeric cost to each path
  - step cost c(*state1, action, state2*)
  - our example of path cost is very simple but things can get messy in real scenario

## Formulating Problems

- The process of removing detail from a representation is called Abstraction

## Examples

#### 1. Toy Problems ( to excercise various problem solving methods )
- vacuum world
- 8-puzzle
- N-queens problem

#### 2. Real-world problems ( problems whose solutions people actually care about )
- Route-finding algorithm
- Touring problems
- Traveling salesperson
- Robot navigation

## Searching For Solutions

- The root of the search tree is a **search node**
- The choice of which state to expand is determined by the **search strategy**

## Production system
- is a computer program that provides some form of AI which mainly consists of rules about behavior
- represent knowledge in the form of condition-action pairs called production rules

**1. Sorting Problem**
**2. Water Jug Problem**

```
x < 4 ==> (4, y)
y < 3 ==> (x, 0)
x > 0 ==> (0, y)
y > 0 ==> (x, 0)
x + y >= 4, x < 4, y > 0 ==> (4, y - ( 4- x))
x + y >= 3, x > 0, y < 3 ==> (x - (3 - y), 3)
x + y <= 4, y > 0 ==> (x + y, 0)
x + y <= 3, x > 0 ==> (0, x + y)
```

## Constraint Satisfaction Problem (CSP)

<iframe width="560" height="315" src="https://www.youtube.com/embed/lCrHYT_EhDs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


CSP is charactersized by
- a set of variables **X** = {x<sub>1</sub>, x<sub>2</sub>, ...}
- a set of domains **D** = {d<sub>1</sub>, d<sub>2</sub>, ...} for each variable x<sub>i</sub> with the possible values for that variable
- a set of constraints **C**. Each constraint C<sub>i</sub> involves some subset of the variables and specifies the allowable combinations of values for that subset.


- A state of the problem ins defined by an **assignment** of values to some or al of the variables.
- An assignment that does not violate any constraints is called a **consistent** or legal assignment
